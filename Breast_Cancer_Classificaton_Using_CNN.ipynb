{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb8ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "INPUT_DATASET = \"datasets/original\"\n",
    "BASE_PATH = \"datasets/idc\"\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH =os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976d0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building validation set\n",
      "Building testing set\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import random, shutil, os\n",
    "originalPaths=list(paths.list_images(INPUT_DATASET))\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "index=int(len(originalPaths)*TRAIN_SPLIT)\n",
    "trainPaths =originalPaths[:index]\n",
    "testPaths=originalPaths[index:]\n",
    "index = int(len(trainPaths)*VAL_SPLIT)\n",
    "valPaths=trainPaths[:index]\n",
    "trainPaths=trainPaths[index:] \n",
    "datasets=[(\"training\", trainPaths, TRAIN_PATH), \n",
    "          (\"validation\", valPaths, VAL_PATH), \n",
    "          (\"testing\", testPaths, TEST_PATH)]\n",
    "\n",
    "for (setType, originalPaths, basePath) in datasets:\n",
    "          print(f'Building {setType} set')\n",
    "          if not os.path.exists(basePath):\n",
    "              print(f'Building directory {basePath}')\n",
    "              os.makedirs(basePath)\n",
    "          for path in originalPaths:\n",
    "              file=path.split(os.path.sep)[-1]\n",
    "              label=file[-5:-4]\n",
    "              labelPath=os.path.sep.join([basePath, label])\n",
    "              if not os.path.exists(labelPath):\n",
    "                  print(f'Building directory {labelPath}')\n",
    "                  os.makedirs(labelPath) \n",
    "              newPath=os.path.sep.join([labelPath, file])\n",
    "              shutil.copy2(path, newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0a8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "class CancerNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        shape = (height, width, depth)\n",
    "        channelDim = -1\n",
    "        \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            shape = (depth, height, width)\n",
    "            channelDim = 1\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=shape))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=classes, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2024b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199818 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                   shear_range= 0.2,\n",
    "                                   zoom_range =0.2, \n",
    "                                   horizontal_flip = True) \n",
    "training_set = train_datagen.flow_from_directory('datasets/idc/training', \n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size =32,\n",
    "                                                 class_mode= 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5264ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199818 images belonging to 2 classes.\n",
      "Found 22201 images belonging to 2 classes.\n",
      "Found 55505 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import to_categorical  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "NUM_EPOCHS=4; INIT_LR=1e-2; BS=32\n",
    "trainPaths=list(paths.list_images (TRAIN_PATH))\n",
    "lenTrain=len(trainPaths)\n",
    "lenVal = len(list(paths.list_images (VAL_PATH)))\n",
    "lenTest = len(list(paths.list_images(TEST_PATH)))\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=to_categorical(trainLabels)  \n",
    "classTotals =trainLabels.sum(axis=0)\n",
    "classWeight=classTotals.max()/classTotals\n",
    "\n",
    "trainAug=ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48,48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BS)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48,48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS)\n",
    "\n",
    "testGen =valAug.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    class_mode=\"categorical\", \n",
    "    target_size=(48,48),\n",
    "    color_mode=\"rgb\", \n",
    "    shuffle=False,\n",
    "    batch_size=BS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6ca049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 46, 46, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 23, 23, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 21, 21, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 19, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 19, 19, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 9, 9, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 7, 7, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 5, 5, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 3, 3, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186690 (729.26 KB)\n",
      "Trainable params: 185474 (724.51 KB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CancerNet.build(width=48,height=48, depth=3, classes=2)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df6a4c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ARGHAYADIP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6245/6245 [==============================] - 1046s 167ms/step - loss: 0.3936 - accuracy: 0.8318 - val_loss: 1.3271 - val_accuracy: 0.7444\n",
      "Epoch 2/40\n",
      "6245/6245 [==============================] - 1155s 185ms/step - loss: 0.3506 - accuracy: 0.8506 - val_loss: 0.5219 - val_accuracy: 0.7322\n",
      "Epoch 3/40\n",
      "6245/6245 [==============================] - 252s 40ms/step - loss: 0.3357 - accuracy: 0.8584 - val_loss: 0.3468 - val_accuracy: 0.8504\n",
      "Epoch 4/40\n",
      "6245/6245 [==============================] - 256s 41ms/step - loss: 0.3303 - accuracy: 0.8614 - val_loss: 0.4518 - val_accuracy: 0.8331\n",
      "Epoch 5/40\n",
      "6245/6245 [==============================] - 252s 40ms/step - loss: 0.3236 - accuracy: 0.8650 - val_loss: 0.4665 - val_accuracy: 0.8244\n",
      "Epoch 6/40\n",
      "6245/6245 [==============================] - 257s 41ms/step - loss: 0.3190 - accuracy: 0.8658 - val_loss: 0.8345 - val_accuracy: 0.7519\n",
      "Epoch 7/40\n",
      "6245/6245 [==============================] - 260s 42ms/step - loss: 0.3162 - accuracy: 0.8672 - val_loss: 0.6710 - val_accuracy: 0.7473\n",
      "Epoch 8/40\n",
      "6245/6245 [==============================] - 367s 59ms/step - loss: 0.3153 - accuracy: 0.8683 - val_loss: 0.3717 - val_accuracy: 0.8426\n",
      "Epoch 9/40\n",
      "6245/6245 [==============================] - 304s 49ms/step - loss: 0.3129 - accuracy: 0.8690 - val_loss: 0.5788 - val_accuracy: 0.7884\n",
      "Epoch 10/40\n",
      "6245/6245 [==============================] - 253s 41ms/step - loss: 0.3109 - accuracy: 0.8701 - val_loss: 0.3605 - val_accuracy: 0.8535\n",
      "Epoch 11/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.3084 - accuracy: 0.8713 - val_loss: 0.4103 - val_accuracy: 0.8389\n",
      "Epoch 12/40\n",
      "6245/6245 [==============================] - 335s 54ms/step - loss: 0.3078 - accuracy: 0.8718 - val_loss: 0.3490 - val_accuracy: 0.8642\n",
      "Epoch 13/40\n",
      "6245/6245 [==============================] - 256s 41ms/step - loss: 0.3051 - accuracy: 0.8727 - val_loss: 0.3400 - val_accuracy: 0.8666\n",
      "Epoch 14/40\n",
      "6245/6245 [==============================] - 257s 41ms/step - loss: 0.3038 - accuracy: 0.8728 - val_loss: 0.4035 - val_accuracy: 0.8520\n",
      "Epoch 15/40\n",
      "6245/6245 [==============================] - 354s 57ms/step - loss: 0.3021 - accuracy: 0.8739 - val_loss: 0.3684 - val_accuracy: 0.8439\n",
      "Epoch 16/40\n",
      "6245/6245 [==============================] - 253s 41ms/step - loss: 0.3009 - accuracy: 0.8745 - val_loss: 0.5448 - val_accuracy: 0.8068\n",
      "Epoch 17/40\n",
      "6245/6245 [==============================] - 325s 52ms/step - loss: 0.2998 - accuracy: 0.8750 - val_loss: 0.3427 - val_accuracy: 0.8667\n",
      "Epoch 18/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2997 - accuracy: 0.8754 - val_loss: 0.3757 - val_accuracy: 0.8492\n",
      "Epoch 19/40\n",
      "6245/6245 [==============================] - 259s 42ms/step - loss: 0.2976 - accuracy: 0.8761 - val_loss: 0.5711 - val_accuracy: 0.7528\n",
      "Epoch 20/40\n",
      "6245/6245 [==============================] - 265s 42ms/step - loss: 0.2965 - accuracy: 0.8762 - val_loss: 0.5772 - val_accuracy: 0.7057\n",
      "Epoch 21/40\n",
      "6245/6245 [==============================] - 256s 41ms/step - loss: 0.2947 - accuracy: 0.8769 - val_loss: 0.4443 - val_accuracy: 0.8326\n",
      "Epoch 22/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2945 - accuracy: 0.8780 - val_loss: 0.4162 - val_accuracy: 0.8623\n",
      "Epoch 23/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2933 - accuracy: 0.8778 - val_loss: 0.3355 - val_accuracy: 0.8518\n",
      "Epoch 24/40\n",
      "6245/6245 [==============================] - 645s 103ms/step - loss: 0.2926 - accuracy: 0.8781 - val_loss: 0.3121 - val_accuracy: 0.8705\n",
      "Epoch 25/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2921 - accuracy: 0.8781 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 26/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2924 - accuracy: 0.8778 - val_loss: 0.3267 - val_accuracy: 0.8649\n",
      "Epoch 27/40\n",
      "6245/6245 [==============================] - 254s 41ms/step - loss: 0.2909 - accuracy: 0.8796 - val_loss: 0.3405 - val_accuracy: 0.8656\n",
      "Epoch 28/40\n",
      "6245/6245 [==============================] - 256s 41ms/step - loss: 0.2894 - accuracy: 0.8795 - val_loss: 0.3380 - val_accuracy: 0.8648\n",
      "Epoch 29/40\n",
      "6245/6245 [==============================] - 254s 41ms/step - loss: 0.2891 - accuracy: 0.8797 - val_loss: 0.4577 - val_accuracy: 0.8335\n",
      "Epoch 30/40\n",
      "6245/6245 [==============================] - 1344s 215ms/step - loss: 0.2885 - accuracy: 0.8798 - val_loss: 0.3242 - val_accuracy: 0.8684\n",
      "Epoch 31/40\n",
      "6245/6245 [==============================] - 418s 67ms/step - loss: 0.2878 - accuracy: 0.8804 - val_loss: 1.7549 - val_accuracy: 0.7793\n",
      "Epoch 32/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2863 - accuracy: 0.8811 - val_loss: 0.3533 - val_accuracy: 0.8496\n",
      "Epoch 33/40\n",
      "6245/6245 [==============================] - 254s 41ms/step - loss: 0.2875 - accuracy: 0.8805 - val_loss: 0.4336 - val_accuracy: 0.8628\n",
      "Epoch 34/40\n",
      "6245/6245 [==============================] - 254s 41ms/step - loss: 0.2858 - accuracy: 0.8810 - val_loss: 0.3883 - val_accuracy: 0.8339\n",
      "Epoch 35/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2865 - accuracy: 0.8815 - val_loss: 5.7429 - val_accuracy: 0.7381\n",
      "Epoch 36/40\n",
      "6245/6245 [==============================] - 702s 112ms/step - loss: 0.2866 - accuracy: 0.8814 - val_loss: 0.3549 - val_accuracy: 0.8763\n",
      "Epoch 37/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2854 - accuracy: 0.8821 - val_loss: 0.3708 - val_accuracy: 0.8416\n",
      "Epoch 38/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2852 - accuracy: 0.8819 - val_loss: 1.8720 - val_accuracy: 0.8248\n",
      "Epoch 39/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2845 - accuracy: 0.8817 - val_loss: 0.3026 - val_accuracy: 0.8755\n",
      "Epoch 40/40\n",
      "6245/6245 [==============================] - 255s 41ms/step - loss: 0.2826 - accuracy: 0.8829 - val_loss: 0.7999 - val_accuracy: 0.6540\n"
     ]
    }
   ],
   "source": [
    "M=model.fit(x = trainGen,validation_data =valGen, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5bc58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARGHAYADIP\\AppData\\Local\\Temp\\ipykernel_19532\\188905018.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred_indices = model.predict_generator(testGen, steps=(lenTest//BS)+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.69     39736\n",
      "           1       0.44      0.89      0.59     15769\n",
      "\n",
      "    accuracy                           0.65     55505\n",
      "   macro avg       0.68      0.72      0.64     55505\n",
      "weighted avg       0.79      0.65      0.66     55505\n",
      "\n",
      "[[21946 17790]\n",
      " [ 1702 14067]]\n",
      "Accuracy: 0.6488244302315107\n",
      "Specificity: 0.8920667131714123\n",
      "Sensitivity: 0.5522951479766459\n"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices = model.predict_generator(testGen, steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices = np.argmax(pred_indices, axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm = confusion_matrix(testGen.classes, pred_indices)\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / total\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1]) \n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "num_epochs = len(M.history['loss'])\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, num_epochs + 1), M.history[\"loss\"], label=\"train_loss\") \n",
    "plt.plot(np.arange(1, num_epochs + 1), M.history[\"val_loss\"], label=\"val_loss\")  \n",
    "plt.plot(np.arange(1, num_epochs + 1), M.history[\"accuracy\"], label=\"train_accuracy\")  \n",
    "plt.plot(np.arange(1, num_epochs + 1), M.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\") \n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debbfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
